@misc{wang2024largelanguagemodelseducation,
      title={Large Language Models for Education: A Survey and Outlook}, 
      author={Shen Wang and Tianlong Xu and Hang Li and Chaoli Zhang and Joleen Liang and Jiliang Tang and Philip S. Yu and Qingsong Wen},
      year={2024},
      eprint={2403.18105},
      archivePrefix={arXiv},
      primaryClass={cs.CL},
      url={https://arxiv.org/abs/2403.18105}, 
}

@inproceedings{10.1145/3641554.3701863,
author = {Raihan, Nishat and Siddiq, Mohammed Latif and Santos, Joanna C.S. and Zampieri, Marcos},
title = {Large Language Models in Computer Science Education: A Systematic Literature Review},
year = {2025},
isbn = {9798400705311},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3641554.3701863},
doi = {10.1145/3641554.3701863},
abstract = {Large language models (LLMs) are becoming increasingly better at a wide range of Natural Language Processing tasks (NLP), such as text generation and understanding. Recently, these models have extended their capabilities to coding tasks, bridging the gap between natural languages (NL) and programming languages (PL). Foundational models such as the Generative Pre-trained Transformer (GPT) and LLaMA series have set strong baseline performances in various NL and PL tasks. Additionally, several models have been fine-tuned specifically for code generation, showing significant improvements in code-related applications. Both foundational and fine-tuned models are increasingly used in education, helping students write, debug, and understand code. We present a comprehensive systematic literature review to examine the impact of LLMs in computer science and computer engineering education. We analyze their effectiveness in enhancing the learning experience, supporting personalized education, and aiding educators in curriculum development. We address five research questions to uncover insights into how LLMs contribute to educational outcomes, identify challenges, and suggest directions for future research.},
booktitle = {Proceedings of the 56th ACM Technical Symposium on Computer Science Education V. 1},
pages = {938–944},
numpages = {7},
keywords = {code generation, cs education, large language models},
location = {Pittsburgh, PA, USA},
series = {SIGCSETS 2025}
}

@inproceedings{srivastava-goodman-2021-question,
    title = "Question Generation for Adaptive Education",
    author = "Srivastava, Megha  and
      Goodman, Noah",
    editor = "Zong, Chengqing  and
      Xia, Fei  and
      Li, Wenjie  and
      Navigli, Roberto",
    booktitle = "Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 2: Short Papers)",
    month = aug,
    year = "2021",
    address = "Online",
    publisher = "Association for Computational Linguistics",
    url = "https://aclanthology.org/2021.acl-short.88/",
    doi = "10.18653/v1/2021.acl-short.88",
    pages = "692--701",
    abstract = "Intelligent and adaptive online education systems aim to make high-quality education available for a diverse range of students. However, existing systems usually depend on a pool of hand-made questions, limiting how fine-grained and open-ended they can be in adapting to individual students. We explore targeted question generation as a controllable sequence generation task. We first show how to fine-tune pre-trained language models for deep knowledge tracing (LM-KT). This model accurately predicts the probability of a student answering a question correctly, and generalizes to questions not seen in training. We then use LM-KT to specify the objective and data for training a model to generate questions conditioned on the student and target difficulty. Our results show we succeed at generating novel, well-calibrated language translation questions for second language learners from a real online education platform."
}

@Article{app14104115,
AUTHOR = {Jošt, Gregor and Taneski, Viktor and Karakatič, Sašo},
TITLE = {The Impact of Large Language Models on Programming Education and Student Learning Outcomes},
JOURNAL = {Applied Sciences},
VOLUME = {14},
YEAR = {2024},
NUMBER = {10},
ARTICLE-NUMBER = {4115},
URL = {https://www.mdpi.com/2076-3417/14/10/4115},
ISSN = {2076-3417},
ABSTRACT = {Recent advancements in Large Language Models (LLMs) like ChatGPT and Copilot have led to their integration into various educational domains, including software development education. Regular use of LLMs in the learning process is still not well-researched; thus, this paper intends to fill this gap. The paper explores the nuanced impact of informal LLM usage on undergraduate students’ learning outcomes in software development education, focusing on React applications. We carefully designed an experiment involving thirty-two participants over ten weeks where we examined unrestricted but not specifically encouraged LLM use and their correlation with student performance. Our results reveal a significant negative correlation between increased LLM reliance for critical thinking-intensive tasks such as code generation and debugging and lower final grades. Furthermore, a downward trend in final grades is observed with increased average LLM use across all tasks. However, the correlation between the use of LLMs for seeking additional explanations and final grades was not as strong, indicating that LLMs may serve better as a supplementary learning tool. These findings highlight the importance of balancing LLM integration with the cultivation of independent problem-solving skills in programming education.},
DOI = {10.3390/app14104115}
}


@Article{educsci13121216,
AUTHOR = {Gligorea, Ilie and Cioca, Marius and Oancea, Romana and Gorski, Andra-Teodora and Gorski, Hortensia and Tudorache, Paul},
TITLE = {Adaptive Learning Using Artificial Intelligence in e-Learning: A Literature Review},
JOURNAL = {Education Sciences},
VOLUME = {13},
YEAR = {2023},
NUMBER = {12},
ARTICLE-NUMBER = {1216},
URL = {https://www.mdpi.com/2227-7102/13/12/1216},
ISSN = {2227-7102},
ABSTRACT = {The rapid evolution of e-learning platforms, propelled by advancements in artificial intelligence (AI) and machine learning (ML), presents a transformative potential in education. This dynamic landscape necessitates an exploration of AI/ML integration in adaptive learning systems to enhance educational outcomes. This study aims to map the current utilization of AI/ML in e-learning for adaptive learning, elucidating the benefits and challenges of such integration and assessing its impact on student engagement, retention, and performance. A comprehensive literature review was conducted, focusing on articles published from 2010 onwards, to document the integration of AI/ML in e-learning. The review analyzed 63 articles, employing a systematic approach to evaluate the deployment of adaptive learning algorithms and their educational implications. Findings reveal that AI/ML algorithms are instrumental in personalizing learning experiences. These technologies have been shown to optimize learning paths, enhance engagement, and improve academic performance, with some studies reporting increased test scores. The integration of AI/ML in e-learning platforms significantly contributes to the personalization and effectiveness of the educational process. Despite challenges like data privacy and the complexity of AI/ML systems, the results underscore the potential of adaptive learning to revolutionize education by catering to individual learner needs.},
DOI = {10.3390/educsci13121216}
}


@article{katona_ai-based_2025,
	title = {{AI}-based Adaptive Programming Education for Socially Disadvantaged Students: Bridging the Digital Divide},
	volume = {69},
	issn = {1559-7075},
	url = {https://doi.org/10.1007/s11528-025-01088-8},
	doi = {10.1007/s11528-025-01088-8},
	shorttitle = {{AI}-based Adaptive Programming Education for Socially Disadvantaged Students},
	abstract = {In the context of the digital economy, programming proficiency is an essential competency that promotes upward socio-economic mobility and expands career opportunities. However, students from socially disadvantaged backgrounds often face significant barriers to acquiring these skills, such as limited access to technology and educational resources. This study explores the impact of {AI}-based adaptive programming education on socially disadvantaged students' learning outcomes and engagement levels. The 122 participants in the research were divided into an experimental group ({EG}) that received {AI}-driven adaptive instruction, and a control group ({CG}) taught through the traditional curriculum during the 13-week experimental period. In the research, the combined pre-test/post-test assessments and self-report engagement questionnaires were used to focus on behavioural, emotional, and cognitive engagement. The findings showed that the {EG} demonstrated higher levels in programming knowledge and full-scale engagement across behavioural, emotional, and cognitive dimensions compared to the {CG}. This difference was confirmed through {ANOVA}, while {ANCOVA}, which controlled for students' socio-economic factors, further confirmed that the {AI} system had a positive impact on students’ results regardless of their socio-economic background. Indeed, current research findings suggest that {AI}-based adaptive learning environments can hold a promising opportunity to narrow educational gaps, boost engagement, and contribute toward better learning outcomes for socially disadvantaged students.},
	pages = {925--942},
	number = {5},
	journaltitle = {{TechTrends}},
	shortjournal = {{TechTrends}},
	author = {Katona, Jozsef and Gyonyoru, Klara Ida Katonane},
	urldate = {2025-11-10},
	date = {2025-09-01},
	langid = {english},
	keywords = {Adaptive learning, {AI}-based education, Disadvantaged students, Programming education, Student engagement},
	file = {Full Text PDF:C\:\\Users\\FIONN MC GOLDRICK\\Zotero\\storage\\KACE3HGY\\Katona and Gyonyoru - 2025 - AI-based Adaptive Programming Education for Socially Disadvantaged Students Bridging the Digital Di.pdf:application/pdf},
}

@inproceedings{Jacobs_2024,
   title={Evaluating the Application of Large Language Models to Generate Feedback in Programming Education},
   url={http://dx.doi.org/10.1109/EDUCON60312.2024.10578838},
   DOI={10.1109/educon60312.2024.10578838},
   booktitle={2024 IEEE Global Engineering Education Conference (EDUCON)},
   publisher={IEEE},
   author={Jacobs, Sven and Jaschke, Steffen},
   year={2024},
   month=may, pages={1–5} }

